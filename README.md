# Backend Challenge â€“ Async Event Processing (Python)

Este proyecto implementa la soluciÃ³n al **Technical Challenge â€” Backend Developer (Python/.NET)**, donde se debe procesar un flujo asÃ­ncrono de eventos en tiempo real garantizando:

- **Orden por llamada** (per-call ordering)
- **Concurrencia mÃ¡xima configurada entre llamadas**
- **Backpressure** cuando se excede el lÃ­mite de llamadas activas
- **FinalizaciÃ³n correcta y ordenada** cuando termina el stream de eventos

La soluciÃ³n estÃ¡ desarrollada exclusivamente con `asyncio`, sin librerÃ­as externas.

---

## DescripciÃ³n del Problema

El sistema recibe un *async stream* de eventos (`CallEvent`), cada uno asociado a un `call_id`.
Debemos procesarlos con la funciÃ³n ya provista `handle_event(call_id, event)`.

La funciÃ³n requerida:

```python
async def process_event_stream(events: AsyncIterator[CallEvent]) -> None:
    ...
```

Cumple los siguientes requerimientos:

### âœ” R1 â€“ Per-call ordering
Los eventos de cada `call_id` deben procesarse en **orden de llegada**.

### âœ” R2 â€“ Concurrency across calls
Diferentes llamadas pueden procesarse en paralelo, hasta un mÃ¡ximo definido:

```python
MAX_CONCURRENT_CALLS = 10
```

### âœ” R3 â€“ Backpressure
Si ya existen 10 llamadas procesÃ¡ndose, un nuevo `call_id` debe esperar a que una finalice.

### âœ” R4 â€“ Graceful Shutdown
Cuando el stream finaliza, se debe esperar la finalizaciÃ³n de **todas las tareas activas** antes de retornar.

---

## ğŸ—ï¸ Arquitectura de la SoluciÃ³n

La implementaciÃ³n utiliza los siguientes componentes:

### ğŸ”¹ 1. Una `asyncio.Queue` por cada `call_id`
Asegura orden y procesamiento secuencial.

### ğŸ”¹ 2. Un worker asÃ­ncrono por llamada
Cada worker:
- Procesa eventos secuencialmente
- Mantiene el semÃ¡foro adquirido
- Libera el semÃ¡foro al finalizar

### ğŸ”¹ 3. Un `asyncio.Semaphore` para controlar concurrencia
Evita que mÃ¡s de `MAX_CONCURRENT_CALLS` llamadas estÃ©n en proceso simultÃ¡neo.

### ğŸ”¹ 4. Un sentinel (`None`) para indicar fin de cada cola
Permite al worker finalizar cuando ya no habrÃ¡ mÃ¡s eventos.

### ğŸ”¹ 5. `asyncio.gather()` para esperar workers al finalizar
Garantiza el **graceful shutdown**.

---

## â–¶ï¸ EjecuciÃ³n

Ejecuta el script directamente:

```bash
python main.py
```

Se utiliza `fake_event_stream()` para pruebas manuales.

---

## ğŸ§ª CÃ³mo Probar el SemÃ¡foro
Activar logs para verificar que **nunca hay mÃ¡s de 10 llamadas activas**.

Ejemplo de debug dentro del worker:

```python
print(f"[START] {call_id} active={active_calls}")
print(f"[END]   {call_id} active={active_calls}")
```

Si el semÃ¡foro funciona, `active` nunca serÃ¡ mayor a `MAX_CONCURRENT_CALLS`.

---

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md

```

---

## ğŸ”§ Requisitos

- Python 3.13+
- No se requieren dependencias externas

---

## ğŸ“Œ Notas

Esta soluciÃ³n estÃ¡ diseÃ±ada para ejecutarse dentro de un servicio de larga vida.
No usa variables globales compartidas en el sistema (solo para debugging). Se prioriza
claridad, aislamiento de tasks y robustez.
